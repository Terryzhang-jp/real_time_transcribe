<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>实时语音转写和翻译</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/socket.io/4.0.1/socket.io.js"></script>
    <style>
        canvas {
            border: 1px solid black;
            margin-top: 10px;
        }
        #transcription, #translation {
            margin-top: 20px;
            padding: 10px;
            border: 1px solid #ccc;
            min-height: 100px;
        }
        #diagram-container {
            margin: 20px;
            padding: 10px;
            border: 1px solid #ccc;
            border-radius: 5px;
            min-height: 200px;
            display: flex;
            justify-content: center;
            align-items: center;
        }
        .error-message {
            color: red;
            text-align: center;
        }
        #diagram-status {
            margin-top: 10px;
            font-style: italic;
            color: #666;
        }
    </style>
</head>
<body>
    <h1>实时语音转写和翻译</h1>
    <select id="languageSelect">
        <option value="">请选择语言</option>
        <option value="zh">中文</option>
        <option value="en">英语</option>
        <option value="ja">日语</option>
    </select>
    <button id="startButton" disabled>开始</button>
    <button id="stopButton" disabled>停止</button>
    <p id="status">未检测到人声</p>
    <p id="frequency">主要频率: - Hz</p>
    <p id="continuity">语音连续性: -</p>
    <p id="volume">当前音量: - dB</p>
    <canvas id="frequencyVisualizer" width="400" height="200"></canvas>
    <canvas id="continuityVisualizer" width="400" height="100"></canvas>
    <canvas id="volumeVisualizer" width="400" height="100"></canvas>
    <h2>转写结果：</h2>
    <div id="transcription"></div>
    <h2>翻译结果（中文）：</h2>
    <div id="translation"></div>
    <h2>GPT-4 修正结果：</h2>
    <div id="corrected-text"></div>
    <h2>实时逻辑流程图：</h2>
    <div id="graph-container">
        <img id="logic-graph" style="max-width: 100%; height: auto; display: none;" />
        <div id="graph-status" style="padding: 10px; margin: 10px 0; background-color: #f5f5f5; border-radius: 4px;">
            等待语音输入...
        </div>
        <!-- 添加详细状态显示 -->
        <div id="graph-details" style="font-size: 0.9em; color: #666;">
            上次更新: <span id="last-update-time">从未更新</span><br>
            当前状态: <span id="current-status">初始化</span><br>
            错误信息: <span id="error-message" style="color: red;"></span>
        </div>
    </div>

    <script>
        let audioContext;
        let analyser;
        let microphone;
        let isListening = false;
        const startButton = document.getElementById('startButton');
        const stopButton = document.getElementById('stopButton');
        const status = document.getElementById('status');
        const frequencyDisplay = document.getElementById('frequency');
        const continuityDisplay = document.getElementById('continuity');
        const volumeDisplay = document.getElementById('volume');
        const frequencyCanvas = document.getElementById('frequencyVisualizer');
        const frequencyCtx = frequencyCanvas.getContext('2d');
        const continuityCanvas = document.getElementById('continuityVisualizer');
        const continuityCtx = continuityCanvas.getContext('2d');
        const volumeCanvas = document.getElementById('volumeVisualizer');
        const volumeCtx = volumeCanvas.getContext('2d');

        const VOLUME_THRESHOLD = -50; // 降低音量阈值，单位为dB
        const MIN_HUMAN_FREQ = 85;
        const MAX_HUMAN_FREQ = 255;
        const CONTINUITY_THRESHOLD = 500; // 连续性阈值，单位为毫秒
        let lastVoiceDetectionTime = 0;
        let continuityBuffer = new Array(300).fill(0);

        let mediaRecorder;
        let audioChunks = [];
        let isTranscribing = false;
        let transcriptionBuffer = '';
        let translationBuffer = '';  // 新增：用于累积翻译结果
        let stream;

        const languageSelect = document.getElementById('languageSelect');
        let selectedLanguage = '';

        languageSelect.onchange = () => {
            selectedLanguage = languageSelect.value;
            startButton.disabled = !selectedLanguage;
        };

        startButton.onclick = async () => {
            if (!selectedLanguage) {
                alert('请先选择语言');
                return;
            }
            stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            audioContext = new (window.AudioContext || window.webkitAudioContext)();
            analyser = audioContext.createAnalyser();
            microphone = audioContext.createMediaStreamSource(stream);

            analyser.fftSize = 2048;
            analyser.smoothingTimeConstant = 0.8;

            microphone.connect(analyser);

            isListening = true;
            detectSound();

            startButton.disabled = true;
            stopButton.disabled = false;

            startRecording();
        };

        stopButton.onclick = () => {
            isListening = false;
            if (audioContext) {
                audioContext.close();
            }
            if (mediaRecorder) {
                mediaRecorder.stop();
            }
            if (stream) {
                stream.getTracks().forEach(track => track.stop());
            }
            startButton.disabled = false;
            stopButton.disabled = true;
            status.textContent = '未检测到人声';
            frequencyDisplay.textContent = '主要频率: - Hz';
            continuityDisplay.textContent = '语音连续性: -';
            volumeDisplay.textContent = '当前音量: - dB';
        };

        function startRecording() {
            audioChunks = [];
            mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm' });
            
            mediaRecorder.ondataavailable = (event) => {
                // 只有当音量超过噪音门限时才添加音频数据
                if (parseFloat(volumeDisplay.textContent.split(': ')[1]) > NOISE_THRESHOLD) {
                    audioChunks.push(event.data);
                }
            };

            mediaRecorder.onstop = () => {
                sendAudioToServer();
                if (isListening) {
                    setTimeout(startRecording, 100); // 100ms后重新开始录音
                }
            };

            mediaRecorder.start();
            setTimeout(() => {
                if (mediaRecorder.state === "recording") {
                    mediaRecorder.stop();
                }
            }, 5000); // 每5秒停止一次录音
        }

        const NOISE_THRESHOLD = -70; // 噪音门限值，单位为dB

        function detectSound() {
            if (!isListening) return;

            const bufferLength = analyser.frequencyBinCount;
            const dataArray = new Float32Array(bufferLength);
            analyser.getFloatFrequencyData(dataArray);

            const nyquist = audioContext.sampleRate / 2;
            const minIndex = Math.floor(MIN_HUMAN_FREQ * bufferLength / nyquist);
            const maxIndex = Math.ceil(MAX_HUMAN_FREQ * bufferLength / nyquist);

            let maxVolume = -Infinity;
            let maxFrequency = 0;
            for (let i = minIndex; i <= maxIndex; i++) {
                if (dataArray[i] > maxVolume) {
                    maxVolume = dataArray[i];
                    maxFrequency = i * nyquist / bufferLength;
                }
            }

            const volumeDB = maxVolume;

            // 可视化频率数据
            visualizeFrequency(dataArray);
            visualizeVolume(volumeDB);

            // 更新音��显示
            volumeDisplay.textContent = `当前音量: ${volumeDB.toFixed(2)} dB`;

            // 输出调试信息到控制台
            // console.log(`Current volume: ${volumeDB.toFixed(2)} dB`);

            // 应用噪音门限
            if (volumeDB > NOISE_THRESHOLD) {
                if (volumeDB > VOLUME_THRESHOLD) {
                    status.textContent = '检测到人声';
                    frequencyDisplay.textContent = `主要频率: ${maxFrequency.toFixed(2)} Hz`;
                    
                    const now = performance.now();
                    const timeSinceLastVoice = now - lastVoiceDetectionTime;
                    lastVoiceDetectionTime = now;

                    if (timeSinceLastVoice < CONTINUITY_THRESHOLD) {
                        continuityDisplay.textContent = '语音连续性: 连续';
                        continuityBuffer.push(1);
                    } else {
                        continuityDisplay.textContent = '语音连续性: 断续';
                        continuityBuffer.push(0);
                    }
                } else {
                    status.textContent = '未检测到人声';
                    frequencyDisplay.textContent = '主要频率: - Hz';
                    continuityDisplay.textContent = '语音连续性: -';
                    continuityBuffer.push(0);
                }
            } else {
                // 音量低于噪音门限，视为无声音
                status.textContent = '静音';
                frequencyDisplay.textContent = '主要频率: - Hz';
                continuityDisplay.textContent = '语音连续性: -';
                continuityBuffer.push(0);
            }

            continuityBuffer.shift();
            visualizeContinuity();

            requestAnimationFrame(detectSound);
        }

        function visualizeFrequency(dataArray) {
            frequencyCtx.fillStyle = 'rgb(200, 200, 200)';
            frequencyCtx.fillRect(0, 0, frequencyCanvas.width, frequencyCanvas.height);
            frequencyCtx.lineWidth = 2;
            frequencyCtx.strokeStyle = 'rgb(0, 0, 0)';
            frequencyCtx.beginPath();

            const sliceWidth = frequencyCanvas.width * 1.0 / dataArray.length;
            let x = 0;

            for (let i = 0; i < dataArray.length; i++) {
                const v = (dataArray[i] + 140) / 140;  // normalize
                const y = v * frequencyCanvas.height / 2;

                if (i === 0) {
                    frequencyCtx.moveTo(x, y);
                } else {
                    frequencyCtx.lineTo(x, y);
                }

                x += sliceWidth;
            }

            frequencyCtx.lineTo(frequencyCanvas.width, frequencyCanvas.height / 2);
            frequencyCtx.stroke();
        }

        function visualizeContinuity() {
            continuityCtx.fillStyle = 'rgb(200, 200, 200)';
            continuityCtx.fillRect(0, 0, continuityCanvas.width, continuityCanvas.height);
            
            const barWidth = continuityCanvas.width / continuityBuffer.length;
            continuityCtx.fillStyle = 'rgb(0, 0, 0)';
            
            for (let i = 0; i < continuityBuffer.length; i++) {
                const barHeight = continuityBuffer[i] * continuityCanvas.height;
                continuityCtx.fillRect(i * barWidth, continuityCanvas.height - barHeight, barWidth, barHeight);
            }
        }

        function visualizeVolume(volume) {
            volumeCtx.clearRect(0, 0, volumeCanvas.width, volumeCanvas.height);
            volumeCtx.fillStyle = 'rgb(0, 255, 0)';
            const height = (volume + 140) * volumeCanvas.height / 140;
            volumeCtx.fillRect(0, volumeCanvas.height - height, volumeCanvas.width, height);
        }

        function sendAudioToServer() {
            if (isTranscribing || audioChunks.length === 0) return;
            isTranscribing = true;

            const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
            const formData = new FormData();
            formData.append('audio', audioBlob, 'recording.webm');
            formData.append('language', selectedLanguage);

            fetch('/transcribe', {
                method: 'POST',
                body: formData
            })
            .then(response => response.json())
            .then(data => {
                if (data.transcription) {
                    transcriptionBuffer += data.transcription + ' ';
                    document.getElementById('transcription').textContent = transcriptionBuffer;
                    sendTranscriptionUpdate();  // 添加这一行
                }
                if (data.translation) {
                    translationBuffer += data.translation + ' ';
                    document.getElementById('translation').textContent = translationBuffer;
                }
                if (data.corrected_text) {
                    correctedTextBuffer = data.corrected_text;  // 更新为最新的修正文本
                    document.getElementById('corrected-text').textContent = correctedTextBuffer;
                }
                isTranscribing = false;
            })
            .catch(error => {
                console.error('Error:', error);
                isTranscribing = false;
            });
        }

        // 新增：清除按和相应的函数
        const clearButton = document.createElement('button');
        clearButton.textContent = '清除结果';
        clearButton.onclick = clearResults;
        document.body.insertBefore(clearButton, document.getElementById('transcription').previousElementSibling);

        function clearResults() {
            transcriptionBuffer = '';
            translationBuffer = '';
            correctedTextBuffer = '';
            document.getElementById('transcription').textContent = '';
            document.getElementById('translation').textContent = '';
            document.getElementById('corrected-text').textContent = '';
        }

        let socket = io();

        // 添加连接状态处理
        socket.on('connect', () => {
            console.log('WebSocket connected');
            document.getElementById('graph-status').textContent = '图表服务已连接';
        });
        
        socket.on('disconnect', () => {
            console.log('WebSocket disconnected');
            document.getElementById('graph-status').textContent = '图表服务已断开';
        });

        // 改进的图表更新处理
        socket.on('graph_update', (data) => {
            console.log('Received graph update:', data);
            const graphImg = document.getElementById('logic-graph');
            const statusDiv = document.getElementById('graph-status');
            const currentStatus = document.getElementById('current-status');
            const errorMessage = document.getElementById('error-message');
            const lastUpdateTime = document.getElementById('last-update-time');
            
            if (data.image_data) {
                graphImg.src = data.image_data;
                graphImg.style.display = 'block';
                statusDiv.textContent = '图表已更新';
                currentStatus.textContent = '更新成功';
                errorMessage.textContent = '';
                lastUpdateTime.textContent = new Date().toLocaleTimeString();
                console.log('Graph image updated successfully');
            } else if (data.status) {
                statusDiv.textContent = data.status;
                currentStatus.textContent = data.status;
                graphImg.style.display = 'none';
            } else if (data.error) {
                statusDiv.textContent = '图表生成失败';
                currentStatus.textContent = '生成失败';
                errorMessage.textContent = data.error;
                graphImg.style.display = 'none';
                console.error('Graph generation failed:', data.error);
            }
        });

        // 改进的转写更新发送函数
        function sendTranscriptionUpdate() {
            if (transcriptionBuffer.trim()) {
                console.log('Sending transcription update, content length:', transcriptionBuffer.length);
                document.getElementById('graph-status').textContent = '正在发送转写内容...';
                
                socket.emit('transcription_update', {
                    transcription: transcriptionBuffer
                });
                
                // 添加超时检查
                setTimeout(() => {
                    const status = document.getElementById('graph-status').textContent;
                    if (status === '正在发送转写内容...') {
                        document.getElementById('graph-status').textContent = '等待服务器响应超时';
                        console.warn('Graph generation timeout');
                    }
                }, 10000);
            }
        }

        // 错误处理
        socket.on('connect_error', (error) => {
            console.error('WebSocket connection error:', error);
            document.getElementById('graph-status').textContent = 'WebSocket 连接错误';
        });

        // 在转写结果更新的地方添加
        socket.on('transcription', function(data) {
            if (data.transcription) {
                transcriptionBuffer += data.transcription + ' ';
                document.getElementById('transcription').textContent = transcriptionBuffer;
                sendTranscriptionUpdate();  // 当有新的转写结果时也触发更新
            }
        });

        // 添加更多的状态监听
        socket.on('graph_status', (data) => {
            document.getElementById('current-status').textContent = data.status;
            document.getElementById('graph-status').textContent = data.status;
        });
    </script>
</body>
</html>
